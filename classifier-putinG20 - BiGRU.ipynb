{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line (header) looks like this:\n",
      "\n",
      "ï»¿text;vaderLabel\n",
      "\n",
      "Each data point looks like this:\n",
      "\n",
      "@SNMilitary Welcome Rusia to bali on G20, ðŸ‡®ðŸ‡©  waiting  ðŸ‡·ðŸ‡º;Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./ReadyData_PutinG20.csv\", 'r', encoding='utf8') as csvfile:\n",
    "    print(f\"First line (header) looks like this:\\n\\n{csvfile.readline()}\")\n",
    "    print(f\"Each data point looks like this:\\n\\n{csvfile.readline()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading & Preprocessing Data\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    # List of stopwords\n",
    "    stopwords = [\"rt\", \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "    \n",
    "    # Sentence converted to lowercase-only\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    no_stopwords = sentence.split()\n",
    "    no_stopwords = [w for w in no_stopwords if w not in stopwords]\n",
    "    sentence = \" \".join(no_stopwords)\n",
    "    sentence = re.sub('(?<=\\s)@[\\w]+|(?<=^)@[\\w]+', '', sentence)\n",
    "\n",
    "    alnum = sentence.split()\n",
    "    alnum = [a for a in alnum if a.isalnum()]\n",
    "    sentence = \" \".join(alnum)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def remove_emojis(sentence):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', sentence)\n",
    "\n",
    "def parse_data_from_file(filename):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(filename, 'r', encoding='utf8') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            labels.append(row[1])\n",
    "            sentence = row[0]\n",
    "            sentence = remove_stopwords(sentence)\n",
    "            sentence = remove_emojis(sentence)\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12462 sentences in the dataset.\n",
      "\n",
      "First sentence has 4 words (after removing stopwords).\n",
      "\n",
      "There are 12462 labels in the dataset.\n",
      "\n",
      "The first 5 labels are ['Positive', 'Positive', 'Neutral', 'Negative', 'Negative']\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "sentences, labels = parse_data_from_file(\"./ReadyData_PutinG20.csv\")\n",
    "\n",
    "print(f\"There are {len(sentences)} sentences in the dataset.\\n\")\n",
    "print(f\"First sentence has {len(sentences[0].split())} words (after removing stopwords).\\n\")\n",
    "print(f\"There are {len(labels)} labels in the dataset.\\n\")\n",
    "print(f\"The first 5 labels are {labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list after removing duplicates: ['Positive', 'Neutral', 'Negative']\n"
     ]
    }
   ],
   "source": [
    "# to remove duplicated from list labels\n",
    "result = [] \n",
    "[result.append(x) for x in labels if x not in result] \n",
    "\n",
    "# printing list labels after removal \n",
    "print (\"The list after removing duplicates: \" + str(result)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining useful global variables\n",
    "NUM_WORDS = 500\n",
    "EMBEDDING_DIM = 16\n",
    "avg_sentence = sum( map(len, sentences) ) / len(sentences)\n",
    "MAXLEN = round(avg_sentence)\n",
    "PADDING = 'post'\n",
    "OOV_TOKEN = \"<OOV>\"\n",
    "TRAINING_SPLIT = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Training & Validation Spli ##\n",
    "\n",
    "# def train_val_split(sentences, labels, training_split):\n",
    "    \n",
    "#     # Compute the number of sentences that will be used for training (should be an integer)\n",
    "#     train_size = int(len(sentences) * training_split)\n",
    "\n",
    "#     # Split the sentences and labels into train/validation splits\n",
    "#     train_sentences = sentences[:train_size]\n",
    "#     train_labels = labels[:train_size]\n",
    "\n",
    "#     validation_sentences = sentences[train_size:]\n",
    "#     validation_labels = labels[train_size:]\n",
    "    \n",
    "#     return train_sentences, validation_sentences, train_labels, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9969 sentences for training.\n",
      "\n",
      "There are 9969 labels for training.\n",
      "\n",
      "There are 2493 sentences for validation.\n",
      "\n",
      "There are 2493 labels for validation.\n"
     ]
    }
   ],
   "source": [
    "# # Test your function\n",
    "# train_sentences, val_sentences, train_labels, val_labels = train_val_split(sentences, labels, TRAINING_SPLIT)\n",
    "\n",
    "# print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n",
    "# print(f\"There are {len(train_labels)} labels for training.\\n\")\n",
    "# print(f\"There are {len(val_sentences)} sentences for validation.\\n\")\n",
    "# print(f\"There are {len(val_labels)} labels for validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.699967902423367"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(sentences, labels, shuffle=True, stratify=labels,\n",
    "                                                    test_size=0.3, random_state=100)\n",
    "\n",
    "# % of training set\n",
    "len(train_sentences)/len(sentences)\n",
    "print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n",
    "print(f\"There are {len(train_labels)} labels for training.\\n\")\n",
    "print(f\"There are {len(val_sentences)} sentences for validation.\\n\")\n",
    "print(f\"There are {len(val_labels)} labels for validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization - Sequence & Padding ##\n",
    "\n",
    "def fit_tokenizer(train_sentences, num_words, oov_token):\n",
    "        \n",
    "    # Instantiate the Tokenizer class, passing in the correct values for num_words and oov_token\n",
    "    tokenizer = Tokenizer(num_words, oov_token=oov_token)\n",
    "    \n",
    "    # Fit the tokenizer to the training sentences\n",
    "    tokenizer.fit_on_texts(train_sentences)    \n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary contains 1064 words\n",
      "\n",
      "<OOV> token included in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "tokenizer = fit_tokenizer(train_sentences, NUM_WORDS, OOV_TOKEN)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(f\"Vocabulary contains {len(word_index)} words\\n\")\n",
    "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'putin': 2,\n",
       " 'g20': 3,\n",
       " 'vladimir': 4,\n",
       " 'not': 5,\n",
       " 'allowed': 6,\n",
       " 'summit': 7,\n",
       " 'invited': 8,\n",
       " 'will': 9,\n",
       " 'president': 10,\n",
       " 'invite': 11,\n",
       " 'indonesia': 12,\n",
       " 'received': 13,\n",
       " 'news': 14,\n",
       " 'russian': 15,\n",
       " 'approach': 16,\n",
       " 'considers': 17,\n",
       " 'condemned': 18,\n",
       " 'attend': 19,\n",
       " 'hell': 20,\n",
       " 'ukraine': 21,\n",
       " 'war': 22,\n",
       " 'biden': 23,\n",
       " 'russia': 24,\n",
       " 'arrested': 25,\n",
       " 'immediately': 26,\n",
       " 'well': 27,\n",
       " 'views': 28,\n",
       " 'exchanged': 29,\n",
       " 'phone': 30,\n",
       " 'situation': 31,\n",
       " 'bloomberg': 32,\n",
       " 'go': 33,\n",
       " 'indonesian': 34,\n",
       " 'plans': 35,\n",
       " 'claims': 36,\n",
       " 'attends': 37,\n",
       " 'actually': 38,\n",
       " 'get': 39,\n",
       " 'meet': 40,\n",
       " 'attempt': 41,\n",
       " 'pushing': 42,\n",
       " 'continued': 43,\n",
       " 'towards': 44,\n",
       " 'wall': 45,\n",
       " 'volodymyr': 46,\n",
       " 'zelensky': 47,\n",
       " 'breaking': 48,\n",
       " 'moscow': 49,\n",
       " 'let': 50,\n",
       " 'widodo': 51,\n",
       " 'joko': 52,\n",
       " 'just': 53,\n",
       " 'world': 54,\n",
       " 'us': 55,\n",
       " 'announced': 56,\n",
       " 'recall': 57,\n",
       " 'days': 58,\n",
       " 'probably': 59,\n",
       " 'nice': 60,\n",
       " 'giving': 61,\n",
       " 'still': 62,\n",
       " 'confirmed': 63,\n",
       " 'sitting': 64,\n",
       " 'palace': 65,\n",
       " 'accepted': 66,\n",
       " 'advisers': 67,\n",
       " 'conversations': 68,\n",
       " 'whose': 69,\n",
       " 'wants': 70,\n",
       " 'invitation': 71,\n",
       " 'time': 72,\n",
       " 'leave': 73,\n",
       " 'able': 74,\n",
       " 'without': 75,\n",
       " 'surely': 76,\n",
       " 'know': 77,\n",
       " 'bali': 78,\n",
       " 'happen': 79,\n",
       " 'confident': 80,\n",
       " 'really': 81,\n",
       " 'nothing': 82,\n",
       " 'says': 83,\n",
       " 'country': 84,\n",
       " 'group': 85,\n",
       " 'meeting': 86,\n",
       " '20': 87,\n",
       " 'hosts': 88,\n",
       " 'told': 89,\n",
       " 'read': 90,\n",
       " 'happened': 91,\n",
       " 'zelenskyy': 92,\n",
       " 'gain': 93,\n",
       " 'ukrainian': 94,\n",
       " 'numerous': 95,\n",
       " 'ways': 96,\n",
       " 'said': 97,\n",
       " 'host': 98,\n",
       " 'white': 99,\n",
       " 'november': 100,\n",
       " 'house': 101,\n",
       " 'among': 102,\n",
       " 'can': 103,\n",
       " 'show': 104,\n",
       " 'privately': 105,\n",
       " 'though': 106,\n",
       " 'nations': 107,\n",
       " 'maybe': 108,\n",
       " 'start': 109,\n",
       " 'include': 110,\n",
       " '6': 111,\n",
       " 'pressing': 112,\n",
       " 'guest': 113,\n",
       " 'dictators': 114,\n",
       " 'joe': 115,\n",
       " 'removing': 116,\n",
       " 'leadership': 117,\n",
       " 'western': 118,\n",
       " 'systematically': 119,\n",
       " 'arrest': 120,\n",
       " 'also': 121,\n",
       " 'leader': 122,\n",
       " 'reports': 123,\n",
       " 'someone': 124,\n",
       " 'whether': 125,\n",
       " 'secretary': 126,\n",
       " 'offer': 127,\n",
       " 'navalny': 128,\n",
       " 'leaders': 129,\n",
       " 'first': 130,\n",
       " 'welcome': 131,\n",
       " 'travel': 132,\n",
       " 'treasury': 133,\n",
       " 'put': 134,\n",
       " 'presidents': 135,\n",
       " 'citing': 136,\n",
       " 'together': 137,\n",
       " 'middle': 138,\n",
       " 'expelled': 139,\n",
       " 'far': 140,\n",
       " 'purge': 141,\n",
       " 'seldom': 142,\n",
       " 'power': 143,\n",
       " 'boycott': 144,\n",
       " 'no': 145,\n",
       " 'consent': 146,\n",
       " 'attendance': 147,\n",
       " 'participate': 148,\n",
       " 'extended': 149,\n",
       " 'conveyed': 150,\n",
       " 'attending': 151,\n",
       " 'nobody': 152,\n",
       " 'knows': 153,\n",
       " 'criminal': 154,\n",
       " 'now': 155,\n",
       " 'absolutely': 156,\n",
       " 'months': 157,\n",
       " 'agenda': 158,\n",
       " 'expressed': 159,\n",
       " 'publicly': 160,\n",
       " 'zelenskiy': 161,\n",
       " 'democratic': 162,\n",
       " 'countries': 163,\n",
       " 'confirming': 164,\n",
       " 'confirms': 165,\n",
       " 'way': 166,\n",
       " 'exactly': 167,\n",
       " 'crimes': 168,\n",
       " 'face': 169,\n",
       " 'shown': 170,\n",
       " 'international': 171,\n",
       " 'like': 172,\n",
       " 'place': 173,\n",
       " 'going': 174,\n",
       " 'jokowi': 175,\n",
       " 'unconcerned': 176,\n",
       " 'conference': 177,\n",
       " 'isolated': 178,\n",
       " 'spoke': 179,\n",
       " 'need': 180,\n",
       " 'kicked': 181,\n",
       " 'living': 182,\n",
       " 'invasion': 183,\n",
       " 'various': 184,\n",
       " 'aspects': 185,\n",
       " 'global': 186,\n",
       " 'think': 187,\n",
       " 'see': 188,\n",
       " 'em': 189,\n",
       " '4': 190,\n",
       " 'causing': 191,\n",
       " 'crisis': 192,\n",
       " 'coz': 193,\n",
       " 'frustrated': 194,\n",
       " 'hope': 195,\n",
       " 'keep': 196,\n",
       " 'accepts': 197,\n",
       " 'exclude': 198,\n",
       " 'entering': 199,\n",
       " 'murderous': 200,\n",
       " 'refused': 201,\n",
       " 'reported': 202,\n",
       " 'island': 203,\n",
       " 'inviting': 204,\n",
       " 'pentagon': 205,\n",
       " 'spox': 206,\n",
       " 'kirby': 207,\n",
       " 'inappropriate': 208,\n",
       " 'treating': 209,\n",
       " 'budge': 210,\n",
       " 'gone': 211,\n",
       " 'scheduled': 212,\n",
       " 'shows': 213,\n",
       " 'call': 214,\n",
       " 'take': 215,\n",
       " 'good': 216,\n",
       " 'saudi': 217,\n",
       " 'determines': 218,\n",
       " 'imagine': 219,\n",
       " 'never': 220,\n",
       " 'prince': 221,\n",
       " 'jen': 222,\n",
       " 'yet': 223,\n",
       " 'brilliant': 224,\n",
       " 'diplomacy': 225,\n",
       " 'including': 226,\n",
       " 'high': 227,\n",
       " 'mohammed': 228,\n",
       " 'bin': 229,\n",
       " 'psaki': 230,\n",
       " 'decided': 231,\n",
       " 'april': 232,\n",
       " 'disappointing': 233,\n",
       " 'unity': 234,\n",
       " 'sit': 235,\n",
       " 'forget': 236,\n",
       " 'needs': 237,\n",
       " 'preparing': 238,\n",
       " 'next': 239,\n",
       " 'back': 240,\n",
       " 'talked': 241,\n",
       " 'military': 242,\n",
       " 'icc': 243,\n",
       " 'disappointed': 244,\n",
       " '29': 245,\n",
       " '2018': 246,\n",
       " 'buenos': 247,\n",
       " 'aires': 248,\n",
       " 'fived': 249,\n",
       " 'salman': 250,\n",
       " 'day': 251,\n",
       " 'initiated': 252,\n",
       " 'talk': 253,\n",
       " 'according': 254,\n",
       " 'join': 255,\n",
       " 'instead': 256,\n",
       " 'perfect': 257,\n",
       " 'attended': 258,\n",
       " 'msm': 259,\n",
       " 'wind': 260,\n",
       " '1940': 261,\n",
       " 'press': 262,\n",
       " 'may': 263,\n",
       " 'aside': 264,\n",
       " 'obvious': 265,\n",
       " 'escalation': 266,\n",
       " 'stopping': 267,\n",
       " 'event': 268,\n",
       " 'plan': 269,\n",
       " 'off': 270,\n",
       " 'current': 271,\n",
       " 'hosting': 272,\n",
       " 'better': 273,\n",
       " 'goes': 274,\n",
       " 'administration': 275,\n",
       " 'opportunity': 276,\n",
       " 'actions': 277,\n",
       " 'continue': 278,\n",
       " 'table': 279,\n",
       " 'setting': 280,\n",
       " 'summits': 281,\n",
       " 'must': 282,\n",
       " 'allow': 283,\n",
       " 'reason': 284,\n",
       " '2022': 285,\n",
       " 'televised': 286,\n",
       " 'team': 287,\n",
       " 'absolute': 288,\n",
       " 'economies': 289,\n",
       " 'hague': 290,\n",
       " 'becoming': 291,\n",
       " 'showdown': 292,\n",
       " 'every': 293,\n",
       " 'asshole': 294,\n",
       " 'assholes': 295,\n",
       " 'allows': 296,\n",
       " 'economic': 297,\n",
       " 'want': 298,\n",
       " 'gets': 299,\n",
       " 'revealed': 300,\n",
       " 'refusal': 301,\n",
       " 'although': 302,\n",
       " 'audacity': 303,\n",
       " 'investigate': 304,\n",
       " 'sexual': 305,\n",
       " 'ukranian': 306,\n",
       " 'gall': 307,\n",
       " 'one': 308,\n",
       " 'perhaps': 309,\n",
       " 'walk': 310,\n",
       " 'seriously': 311,\n",
       " 'trump': 312,\n",
       " 'set': 313,\n",
       " 'even': 314,\n",
       " 'come': 315,\n",
       " 'cnn': 316,\n",
       " 'peace': 317,\n",
       " 'people': 318,\n",
       " 'piece': 319,\n",
       " 'person': 320,\n",
       " 'forum': 321,\n",
       " 'done': 322,\n",
       " 'excellent': 323,\n",
       " 'cause': 324,\n",
       " 'banned': 325,\n",
       " 'increasingly': 326,\n",
       " 'uncredible': 327,\n",
       " 'eyes': 328,\n",
       " 'ignores': 329,\n",
       " 'values': 330,\n",
       " 'ani': 331,\n",
       " 'pay': 332,\n",
       " 'hosted': 333,\n",
       " 'largest': 334,\n",
       " 'red': 335,\n",
       " 'hopes': 336,\n",
       " 'finance': 337,\n",
       " 'ministers': 338,\n",
       " 'united': 339,\n",
       " 'long': 340,\n",
       " 'thought': 341,\n",
       " 'previously': 342,\n",
       " 'minister': 343,\n",
       " 'doubt': 344,\n",
       " 'sanctions': 345,\n",
       " 'avoid': 346,\n",
       " 'detained': 347,\n",
       " 'questioned': 348,\n",
       " 'invites': 349,\n",
       " 'tell': 350,\n",
       " 'held': 351,\n",
       " 'crafting': 352,\n",
       " 'agreements': 353,\n",
       " 'demonstrated': 354,\n",
       " 'job': 355,\n",
       " 'taken': 356,\n",
       " 'genocide': 357,\n",
       " 'wtf': 358,\n",
       " 'decision': 359,\n",
       " 'sets': 360,\n",
       " 'scene': 361,\n",
       " 'amid': 362,\n",
       " 'serious': 363,\n",
       " 'innocent': 364,\n",
       " 'remove': 365,\n",
       " 'body': 366,\n",
       " 'great': 367,\n",
       " 'sent': 368,\n",
       " 'terrorist': 369,\n",
       " 'cancel': 370,\n",
       " 'unlike': 371,\n",
       " 'committed': 372,\n",
       " 'across': 373,\n",
       " 'stand': 374,\n",
       " 'uncomfortable': 375,\n",
       " 'developed': 376,\n",
       " 'bit': 377,\n",
       " 'pet': 378,\n",
       " 'peeve': 379,\n",
       " 'collocations': 380,\n",
       " 'states': 381,\n",
       " 'move': 382,\n",
       " 'accept': 383,\n",
       " 'roll': 384,\n",
       " 'carpet': 385,\n",
       " 'drag': 386,\n",
       " 'simply': 387,\n",
       " 'human': 388,\n",
       " 'rights': 389,\n",
       " 'believe': 390,\n",
       " 'support': 391,\n",
       " 'prime': 392,\n",
       " 'starts': 393,\n",
       " 'unprovoked': 394,\n",
       " 'kills': 395,\n",
       " 'thousands': 396,\n",
       " 'cold': 397,\n",
       " 'vlad': 398,\n",
       " 'possibly': 399,\n",
       " 'arrives': 400,\n",
       " 'big': 401,\n",
       " 'deal': 402,\n",
       " 'insists': 403,\n",
       " 'currently': 404,\n",
       " 'chairing': 405,\n",
       " 'major': 406,\n",
       " 'heard': 407,\n",
       " 'stay': 408,\n",
       " 'stop': 409,\n",
       " 'murderer': 410,\n",
       " 'known': 411,\n",
       " 'visited': 412,\n",
       " 'ban': 413,\n",
       " 'light': 414,\n",
       " 'money': 415,\n",
       " 'twitter': 416,\n",
       " '27': 417,\n",
       " 'informed': 418,\n",
       " 'fuck': 419,\n",
       " 'part': 420,\n",
       " 'weeks': 421,\n",
       " 'interpol': 422,\n",
       " 'possible': 423,\n",
       " 'two': 424,\n",
       " 'right': 425,\n",
       " 'formally': 426,\n",
       " 'anyone': 427,\n",
       " 'following': 428,\n",
       " 'orders': 429,\n",
       " 'advancing': 430,\n",
       " 'illegal': 431,\n",
       " 'head': 432,\n",
       " 'uk': 433,\n",
       " 'despite': 434,\n",
       " 'widespread': 435,\n",
       " 'accepting': 436,\n",
       " 'tf': 437,\n",
       " 'tweeted': 438,\n",
       " 'security': 439,\n",
       " 'atrocities': 440,\n",
       " 'invaded': 441,\n",
       " 'crown': 442,\n",
       " 'hardship': 443,\n",
       " 'guts': 444,\n",
       " 'change': 445,\n",
       " 'kick': 446,\n",
       " 'china': 447,\n",
       " 'insisting': 448,\n",
       " 'remain': 449,\n",
       " 'ruusia': 450,\n",
       " 'dead': 451,\n",
       " 'business': 452,\n",
       " 'say': 453,\n",
       " 'z': 454,\n",
       " 'unless': 455,\n",
       " 'coordination': 456,\n",
       " 'efforts': 457,\n",
       " 'canadian': 458,\n",
       " 'deputy': 459,\n",
       " 'chrystia': 460,\n",
       " 'freeland': 461,\n",
       " 'staffers': 462,\n",
       " 'appeared': 463,\n",
       " 'ignore': 464,\n",
       " 'questions': 465,\n",
       " 'organizers': 466,\n",
       " 'journalists': 467,\n",
       " 'ask': 468,\n",
       " 'sas': 469,\n",
       " 'asked': 470,\n",
       " 'rest': 471,\n",
       " 'decide': 472,\n",
       " 'refuses': 473,\n",
       " 'east': 474,\n",
       " 'knowing': 475,\n",
       " 'live': 476,\n",
       " 'run': 477,\n",
       " 'dump': 478,\n",
       " 'gathering': 479,\n",
       " 'making': 480,\n",
       " 'west': 481,\n",
       " 'today': 482,\n",
       " 'upcoming': 483,\n",
       " 'afraid': 484,\n",
       " 'got': 485,\n",
       " 'others': 486,\n",
       " 'end': 487,\n",
       " 'mass': 488,\n",
       " 'book': 489,\n",
       " 'asking': 490,\n",
       " 'committing': 491,\n",
       " 'wth': 492,\n",
       " 'planning': 493,\n",
       " 'quoted': 494,\n",
       " 'real': 495,\n",
       " 'cuz': 496,\n",
       " 'stupid': 497,\n",
       " 'per': 498,\n",
       " 'respect': 499,\n",
       " 'personally': 500,\n",
       " 'however': 501,\n",
       " 'given': 502,\n",
       " 'custody': 503,\n",
       " 'declines': 504,\n",
       " 'massacre': 505,\n",
       " 'mean': 506,\n",
       " 'question': 507,\n",
       " 'reportedly': 508,\n",
       " 'saying': 509,\n",
       " 'look': 510,\n",
       " 'intends': 511,\n",
       " 'government': 512,\n",
       " 'greatest': 513,\n",
       " 'assassinate': 514,\n",
       " 'liar': 515,\n",
       " 'coming': 516,\n",
       " 'million': 517,\n",
       " 'bounty': 518,\n",
       " 'telephone': 519,\n",
       " 'demanded': 520,\n",
       " 'watching': 521,\n",
       " 'kill': 522,\n",
       " 'dust': 523,\n",
       " 'lavrov': 524,\n",
       " 'australia': 525,\n",
       " 'humanity': 526,\n",
       " 'bring': 527,\n",
       " '19': 528,\n",
       " 'idea': 529,\n",
       " 'thrown': 530,\n",
       " 'sanctioning': 531,\n",
       " 'crap': 532,\n",
       " 'ru': 533,\n",
       " 'b': 534,\n",
       " 'totally': 535,\n",
       " 'send': 536,\n",
       " 'chair': 537,\n",
       " 'wartime': 538,\n",
       " 'vulnerable': 539,\n",
       " 'outside': 540,\n",
       " 'hand': 541,\n",
       " 'shake': 542,\n",
       " 'wrong': 543,\n",
       " 'make': 544,\n",
       " 'running': 545,\n",
       " 'home': 546,\n",
       " 'shout': 547,\n",
       " 'agreed': 548,\n",
       " 'sadism': 549,\n",
       " 'sending': 550,\n",
       " 'pics': 551,\n",
       " 'mother': 552,\n",
       " 'holder': 553,\n",
       " 'mandate': 554,\n",
       " 'goals': 555,\n",
       " 'everyone': 556,\n",
       " 'ahead': 557,\n",
       " 'wonder': 558,\n",
       " 'g19': 559,\n",
       " 'close': 560,\n",
       " 'seems': 561,\n",
       " 'trial': 562,\n",
       " 'sri': 563,\n",
       " 'mulyani': 564,\n",
       " 'walks': 565,\n",
       " 'follow': 566,\n",
       " 'rejection': 567,\n",
       " 'participation': 568,\n",
       " 'chance': 569,\n",
       " 'maturity': 570,\n",
       " 'eu': 571,\n",
       " 'learn': 572,\n",
       " 'members': 573,\n",
       " 'warrant': 574,\n",
       " 'save': 575,\n",
       " 'charges': 576,\n",
       " 'five': 577,\n",
       " 'please': 578,\n",
       " 'much': 579,\n",
       " 'confront': 580,\n",
       " 'surround': 581,\n",
       " 'hid': 582,\n",
       " 'dealing': 583,\n",
       " 'wish': 584,\n",
       " 'plane': 585,\n",
       " 'protest': 586,\n",
       " 'entourage': 587,\n",
       " 'permanently': 588,\n",
       " 'less': 589,\n",
       " 'idiot': 590,\n",
       " 'order': 591,\n",
       " 'thus': 592,\n",
       " 'spokesman': 593,\n",
       " 'getting': 594,\n",
       " 'mr': 595,\n",
       " 'later': 596,\n",
       " 'usa': 597,\n",
       " 'ever': 598,\n",
       " 'state': 599,\n",
       " 'rides': 600,\n",
       " 'hopefully': 601,\n",
       " 'main': 602,\n",
       " 'cage': 603,\n",
       " 'openly': 604,\n",
       " '18': 605,\n",
       " 'fearful': 606,\n",
       " 'poisoned': 607,\n",
       " 'g': 608,\n",
       " 'south': 609,\n",
       " 'asia': 610,\n",
       " 'meets': 611,\n",
       " 'prerequisites': 612,\n",
       " 'appetite': 613,\n",
       " 'dick': 614,\n",
       " 'ome': 615,\n",
       " 'oppose': 616,\n",
       " 'diplomatic': 617,\n",
       " 'sources': 618,\n",
       " 'near': 619,\n",
       " 'allies': 620,\n",
       " 'balls': 621,\n",
       " 'speech': 622,\n",
       " 'responsible': 623,\n",
       " 'civil': 624,\n",
       " 'insurrection': 625,\n",
       " 'eastern': 626,\n",
       " 'taking': 627,\n",
       " 'sript': 628,\n",
       " 'play': 629,\n",
       " 'pressuring': 630,\n",
       " 'nation': 631,\n",
       " 'dreamt': 632,\n",
       " 'shot': 633,\n",
       " 'scoring': 634,\n",
       " 'couldnt': 635,\n",
       " 'politician': 636,\n",
       " 'thing': 637,\n",
       " 'id': 638,\n",
       " 'attack': 639,\n",
       " 'guarantee': 640,\n",
       " 'hilter': 641,\n",
       " 'signing': 642,\n",
       " 'korea': 643,\n",
       " 'free': 644,\n",
       " 'wishful': 645,\n",
       " 'thinking': 646,\n",
       " 'rescinded': 647,\n",
       " 'enemy': 648,\n",
       " 'slapped': 649,\n",
       " 'opposition': 650,\n",
       " 'made': 651,\n",
       " 'oklahoma': 652,\n",
       " 'bills': 653,\n",
       " 'aim': 654,\n",
       " 'pres': 655,\n",
       " 'loose': 656,\n",
       " 'lead': 657,\n",
       " 'army': 658,\n",
       " 'dressed': 659,\n",
       " 'bubble': 660,\n",
       " 'boy': 661,\n",
       " 'since': 662,\n",
       " 'owned': 663,\n",
       " 'convenient': 664,\n",
       " 'sniper': 665,\n",
       " 'area': 666,\n",
       " 'hopeful': 667,\n",
       " 'anyway': 668,\n",
       " 'happening': 669,\n",
       " 'opinion': 670,\n",
       " 'honour': 671,\n",
       " 'lol': 672,\n",
       " 'bad': 673,\n",
       " 'used': 674,\n",
       " 'pawns': 675,\n",
       " 'isolate': 676,\n",
       " 'try': 677,\n",
       " 'divide': 678,\n",
       " 'responds': 679,\n",
       " 'directly': 680,\n",
       " 'transport': 681,\n",
       " 'supports': 682,\n",
       " 'hi': 683,\n",
       " 'true': 684,\n",
       " 'indicted': 685,\n",
       " 'modern': 686,\n",
       " 'watch': 687,\n",
       " 'youtube': 688,\n",
       " 'india': 689,\n",
       " '2023': 690,\n",
       " 'circumstances': 691,\n",
       " 'recruit': 692,\n",
       " 'sharp': 693,\n",
       " 'shooters': 694,\n",
       " 'evil': 695,\n",
       " 'die': 696,\n",
       " 'cute': 697,\n",
       " 'dollar': 698,\n",
       " 'expose': 699,\n",
       " 'conversation': 700,\n",
       " 'republic': 701,\n",
       " 'rebuttal': 702,\n",
       " 'promises': 703,\n",
       " 'level': 704,\n",
       " 'safe': 705,\n",
       " 'passage': 706,\n",
       " 'gave': 707,\n",
       " 'declared': 708,\n",
       " 'seize': 709,\n",
       " 'point': 710,\n",
       " 'rightly': 711,\n",
       " 'transported': 712,\n",
       " 'piss': 713,\n",
       " 'weak': 714,\n",
       " 'reflected': 715,\n",
       " 'allowing': 716,\n",
       " 'betting': 717,\n",
       " 'via': 718,\n",
       " 'video': 719,\n",
       " 'warring': 720,\n",
       " 'pleased': 721,\n",
       " 'rebuffing': 722,\n",
       " 'demand': 723,\n",
       " 'bar': 724,\n",
       " 'weirdos': 725,\n",
       " 'year': 726,\n",
       " 'germany': 727,\n",
       " 'france': 728,\n",
       " 'turkey': 729,\n",
       " 'canada': 730,\n",
       " 'kind': 731,\n",
       " 'game': 732,\n",
       " 'played': 733,\n",
       " 'henchmen': 734,\n",
       " 'dear': 735,\n",
       " 'pm': 736,\n",
       " 'normalizing': 737,\n",
       " 'atrocity': 738,\n",
       " 'barred': 739,\n",
       " 'mh': 740,\n",
       " '370': 741,\n",
       " 'destruction': 742,\n",
       " 'aware': 743,\n",
       " 'pressure': 744,\n",
       " 'prevent': 745,\n",
       " 'success': 746,\n",
       " 'mtg': 747,\n",
       " 'bright': 748,\n",
       " 'solutions': 749,\n",
       " 'forged': 750,\n",
       " 'speaks': 751,\n",
       " 'seal': 752,\n",
       " 'whatever': 753,\n",
       " 'guys': 754,\n",
       " 'counterpart': 755,\n",
       " 'nuts': 756,\n",
       " 'immediate': 757,\n",
       " 'financial': 758,\n",
       " 'horrific': 759,\n",
       " 'many': 760,\n",
       " 'representatives': 761,\n",
       " 'removed': 762,\n",
       " 'tinfoil': 763,\n",
       " 'hat': 764,\n",
       " 'cat': 765,\n",
       " 'believes': 766,\n",
       " 'supported': 767,\n",
       " 'activities': 768,\n",
       " 'established': 769,\n",
       " 'slap': 770,\n",
       " 'thoughts': 771,\n",
       " 'joke': 772,\n",
       " 'help': 773,\n",
       " 'actual': 774,\n",
       " 'officially': 775,\n",
       " 'comrade': 776,\n",
       " 'globe': 777,\n",
       " 'god': 778,\n",
       " 'legitimate': 779,\n",
       " 'target': 780,\n",
       " 'flies': 781,\n",
       " 'plaque': 782,\n",
       " 'marine': 783,\n",
       " 'american': 784,\n",
       " 'thinks': 785,\n",
       " 'requested': 786,\n",
       " 'arms': 787,\n",
       " 'turned': 788,\n",
       " 'finger': 789,\n",
       " 'hitler': 790,\n",
       " 'suicide': 791,\n",
       " 'european': 792,\n",
       " 'assembly': 793,\n",
       " 'serve': 794,\n",
       " 'slaughters': 795,\n",
       " 'gates': 796,\n",
       " 'fuhrer': 797,\n",
       " 'else': 798,\n",
       " 'normal': 799,\n",
       " 'faculties': 800,\n",
       " 'enable': 801,\n",
       " 'shame': 802,\n",
       " 'interacting': 803,\n",
       " 'boycot': 804,\n",
       " 'warrants': 805,\n",
       " 'throw': 806,\n",
       " 'th': 807,\n",
       " 'legal': 808,\n",
       " 'expert': 809,\n",
       " 'share': 810,\n",
       " 'stage': 811,\n",
       " 'gratitude': 812,\n",
       " 'expect': 813,\n",
       " 'alike': 814,\n",
       " 'treaty': 815,\n",
       " 'observed': 816,\n",
       " 'communities': 817,\n",
       " 'sharing': 818,\n",
       " 'find': 819,\n",
       " 'daydreaming': 820,\n",
       " 'promptly': 821,\n",
       " 'diminished': 822,\n",
       " 'economy': 823,\n",
       " 'matt': 824,\n",
       " 'gaetz': 825,\n",
       " 'junior': 826,\n",
       " 'rocket': 827,\n",
       " 'science': 828,\n",
       " 'syria': 829,\n",
       " 'libya': 830,\n",
       " 'soon': 831,\n",
       " 'walked': 832,\n",
       " 'began': 833,\n",
       " 'speak': 834,\n",
       " 'cell': 835,\n",
       " 'awaiting': 836,\n",
       " 'unexpected': 837,\n",
       " 'meteorological': 838,\n",
       " 'special': 839,\n",
       " 'operations': 840,\n",
       " 'damn': 841,\n",
       " 'messed': 842,\n",
       " 'insist': 843,\n",
       " 'retract': 844,\n",
       " 'reasons': 845,\n",
       " 'apparently': 846,\n",
       " 'worried': 847,\n",
       " 'realise': 848,\n",
       " 'cater': 849,\n",
       " 'vs': 850,\n",
       " 'shall': 851,\n",
       " 'covie': 852,\n",
       " 'past': 853,\n",
       " 'midnight': 854,\n",
       " 'tired': 855,\n",
       " 'nato': 856,\n",
       " 'abstain': 857,\n",
       " 'installed': 858,\n",
       " 'failure': 859,\n",
       " 'declined': 860,\n",
       " 'request': 861,\n",
       " 'weapons': 862,\n",
       " 'due': 863,\n",
       " 'southeast': 864,\n",
       " 'asian': 865,\n",
       " 'foreign': 866,\n",
       " 'result': 867,\n",
       " 'already': 868,\n",
       " 'ready': 869,\n",
       " 'law': 870,\n",
       " 'authorities': 871,\n",
       " 'decline': 872,\n",
       " 'entertain': 873,\n",
       " 'best': 874,\n",
       " 'scenario': 875,\n",
       " 'position': 876,\n",
       " 'succeed': 877,\n",
       " 'dissolved': 878,\n",
       " 'doubts': 879,\n",
       " 'exposure': 880,\n",
       " 'might': 881,\n",
       " 'smart': 882,\n",
       " 'ass': 883,\n",
       " 'deliver': 884,\n",
       " 'till': 885,\n",
       " 'date': 886,\n",
       " 'r': 887,\n",
       " 'disaster': 888,\n",
       " 'gut': 889,\n",
       " 'feeling': 890,\n",
       " 'drop': 891,\n",
       " 'miraculously': 892,\n",
       " 'sky': 893,\n",
       " 'memories': 894,\n",
       " 'watched': 895,\n",
       " 'glad': 896,\n",
       " 'anyhow': 897,\n",
       " 'product': 898,\n",
       " 'unacceptable': 899,\n",
       " 'disgusting': 900,\n",
       " 'afp': 901,\n",
       " 'fixed': 902,\n",
       " 'scorned': 903,\n",
       " 'ex': 904,\n",
       " 'twisted': 905,\n",
       " 'shit': 906,\n",
       " 'reality': 907,\n",
       " 'wh': 908,\n",
       " 'janet': 909,\n",
       " 'yellen': 910,\n",
       " 'leading': 911,\n",
       " 'walkout': 912,\n",
       " 'officials': 913,\n",
       " 'civilized': 914,\n",
       " 'battle': 915,\n",
       " 'gonna': 916,\n",
       " 'ensure': 917,\n",
       " 'geritol': 918,\n",
       " 'oligarchs': 919,\n",
       " 'rebuild': 920,\n",
       " 'knocked': 921,\n",
       " 'private': 922,\n",
       " 'chat': 923,\n",
       " 'sure': 924,\n",
       " 'check': 925,\n",
       " 'supremely': 926,\n",
       " 'richest': 927,\n",
       " 'winning': 928,\n",
       " 'statue': 929,\n",
       " 'delegation': 930,\n",
       " 'address': 931,\n",
       " 'n': 932,\n",
       " 'jerk': 933,\n",
       " 'alone': 934,\n",
       " 'lists': 935,\n",
       " 'places': 936,\n",
       " 'gd': 937,\n",
       " 'willing': 938,\n",
       " 'venue': 939,\n",
       " 'give': 940,\n",
       " 'directions': 941,\n",
       " 'tried': 942,\n",
       " 'tabs': 943,\n",
       " 'direct': 944,\n",
       " 'negotiation': 945,\n",
       " 'nitwit': 946,\n",
       " 'poison': 947,\n",
       " 'tea': 948,\n",
       " 'showing': 949,\n",
       " 'stare': 950,\n",
       " 'hes': 951,\n",
       " 'scott': 952,\n",
       " 'morrison': 953,\n",
       " 'corrupt': 954,\n",
       " 'widely': 955,\n",
       " 'grab': 956,\n",
       " 'new': 957,\n",
       " 'poorly': 958,\n",
       " 'kate': 959,\n",
       " 'bolduan': 960,\n",
       " 're': 961,\n",
       " 'et': 962,\n",
       " 'al': 963,\n",
       " 'meetings': 964,\n",
       " 'gonads': 965,\n",
       " 'murdering': 966,\n",
       " 'children': 967,\n",
       " 'soft': 968,\n",
       " 'serial': 969,\n",
       " 'provide': 970,\n",
       " 'persona': 971,\n",
       " 'non': 972,\n",
       " 'grata': 973,\n",
       " 'illegally': 974,\n",
       " 'occupies': 975,\n",
       " 'territory': 976,\n",
       " 'freeze': 977,\n",
       " 'tv': 978,\n",
       " 'bragged': 979,\n",
       " 'captivated': 980,\n",
       " 'announcing': 981,\n",
       " 'engaged': 982,\n",
       " 'armed': 983,\n",
       " 'included': 984,\n",
       " 'roast': 985,\n",
       " 'yr': 986,\n",
       " 'suit': 987,\n",
       " 'elon': 988,\n",
       " 'musk': 989,\n",
       " 'favor': 990,\n",
       " 'uncivilized': 991,\n",
       " 'animal': 992,\n",
       " 'den': 993,\n",
       " 'dumbass': 994,\n",
       " 'ousted': 995,\n",
       " 'case': 996,\n",
       " 'tries': 997,\n",
       " 'turn': 998,\n",
       " 'braces': 999,\n",
       " 'potential': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_and_pad\n",
    "def seq_and_pad(sentences, tokenizer, padding, maxlen):\n",
    "       \n",
    "    # Convert sentences to sequences\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    \n",
    "    # Pad the sequences using the correct padding and maxlen\n",
    "    padded_sequences = pad_sequences(sequences, padding=padding, maxlen=maxlen)\n",
    "    \n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded training sequences have shape: (8723, 45)\n",
      "\n",
      "Padded validation sequences have shape: (3739, 45)\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_padded_seq = seq_and_pad(train_sentences, tokenizer, PADDING, MAXLEN)\n",
    "val_padded_seq = seq_and_pad(val_sentences, tokenizer, PADDING, MAXLEN)\n",
    "\n",
    "print(f\"Padded training sequences have shape: {train_padded_seq.shape}\\n\")\n",
    "print(f\"Padded validation sequences have shape: {val_padded_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded training sequences:\n",
      " [[  2  13  11 ...   0   0   0]\n",
      " [  4   2   5 ...   0   0   0]\n",
      " [ 17  16   3 ...   0   0   0]\n",
      " ...\n",
      " [224 225  94 ...   0   0   0]\n",
      " [  4   2   5 ...   0   0   0]\n",
      " [ 29  28  30 ...   0   0   0]]\n",
      "\n",
      "Padded validation sequences:\n",
      " [[ 2 13 11 ...  0  0  0]\n",
      " [12  8 15 ...  0  0  0]\n",
      " [20  2  8 ...  0  0  0]\n",
      " ...\n",
      " [20  2  8 ...  0  0  0]\n",
      " [ 2 38 37 ...  0  0  0]\n",
      " [64 65 60 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Padded training sequences:\\n {train_padded_seq}\\n\")\n",
    "print(f\"Padded validation sequences:\\n {val_padded_seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize_labels\n",
    "\n",
    "def tokenize_labels(all_labels, split_labels):\n",
    "    \n",
    "    # Instantiate the Tokenizer (no additional arguments needed)\n",
    "    label_tokenizer = Tokenizer()\n",
    "    \n",
    "    # Fit the tokenizer on all the labels\n",
    "    label_tokenizer.fit_on_texts(all_labels)\n",
    "    \n",
    "    # Convert labels to sequences\n",
    "    label_seq = label_tokenizer.texts_to_sequences(split_labels)\n",
    "    \n",
    "    # Convert sequences to a numpy array. Don't forget to substact 1 from every entry in the array!\n",
    "    label_seq_np = np.array(label_seq) - 1\n",
    "    \n",
    "    return label_seq_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 labels of the training set should look like this:\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "First 5 labels of the validation set should look like this:\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "\n",
      "Tokenized labels of the training set have shape: (8723, 1)\n",
      "\n",
      "Tokenized labels of the validation set have shape: (3739, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_label_seq = tokenize_labels(labels, train_labels)\n",
    "val_label_seq = tokenize_labels(labels, val_labels)\n",
    "\n",
    "print(f\"First 5 labels of the training set should look like this:\\n{train_label_seq[:5]}\\n\")\n",
    "print(f\"First 5 labels of the validation set should look like this:\\n{val_label_seq[:5]}\\n\")\n",
    "print(f\"Tokenized labels of the training set have shape: {train_label_seq.shape}\\n\")\n",
    "print(f\"Tokenized labels of the validation set have shape: {val_label_seq.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 train labels are ['Negative', 'Neutral', 'Negative', 'Neutral', 'Negative']\n",
      "\n",
      "The first 5 validation labels are ['Negative', 'Neutral', 'Negative', 'Negative', 'Neutral']\n",
      "\n",
      "the number of each label in the data:\n",
      " {'Positive': 1675, 'Neutral': 5866, 'Negative': 4921}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The first 5 train labels are {train_labels[:5]}\\n\")\n",
    "print(f\"The first 5 validation labels are {val_labels[:5]}\\n\")\n",
    "\n",
    "# count number of each label in the data\n",
    "res = {}\n",
    "\n",
    "for i in labels:\n",
    "    res[i] = labels.count(i)\n",
    "    \n",
    "print(f\"the number of each label in the data:\\n {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indonesia invited russian putin g20 summit\n",
      "[12  8 15  2  3  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[10])\n",
    "print(train_padded_seq[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 45, 16)            8000      \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               9600      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,011\n",
      "Trainable params: 18,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: create_model\n",
    "def model_GRU(num_words, embedding_dim, maxlen):\n",
    "    \n",
    "    tf.random.set_seed(123)\n",
    "    gru_dim = 32\n",
    "    dense_dim = 6\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    modelGRU = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(num_words, embedding_dim, input_length=maxlen),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(gru_dim)),\n",
    "        tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    modelGRU.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adamax(learning_rate=3e-4),\n",
    "                  metrics=['accuracy']) \n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return modelGRU\n",
    "\n",
    "modelGRU = model_GRU(NUM_WORDS, EMBEDDING_DIM, MAXLEN)\n",
    "modelGRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # myCallback\n",
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#         # Define the correct function signature for on_epoch_end\n",
    "#         def on_epoch_end(self, epoch, logs={}):\n",
    "#             if logs.get('accuracy') is not None and logs.get('accuracy') > 0.95: # @KEEP\n",
    "#                 print(\"\\nReached 95% accuracy so cancelling training!\") \n",
    "                \n",
    "#                 # Stop training once the above condition is met\n",
    "#                 self.model.stop_training = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('classifier-putinG20-BiGRU_04.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "# # es = EarlyStopping(restore_best_weights=True, monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "# callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.9913 - accuracy: 0.4688\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47071, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 6s 13ms/step - loss: 0.9903 - accuracy: 0.4692 - val_loss: 0.9079 - val_accuracy: 0.4707\n",
      "Epoch 2/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.8131 - accuracy: 0.4724\n",
      "Epoch 2: val_accuracy improved from 0.47071 to 0.58813, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.8126 - accuracy: 0.4729 - val_loss: 0.6812 - val_accuracy: 0.5881\n",
      "Epoch 3/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.7980\n",
      "Epoch 3: val_accuracy improved from 0.58813 to 0.82696, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5745 - accuracy: 0.7980 - val_loss: 0.4735 - val_accuracy: 0.8270\n",
      "Epoch 4/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.4111 - accuracy: 0.8547\n",
      "Epoch 4: val_accuracy improved from 0.82696 to 0.90452, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.4114 - accuracy: 0.8549 - val_loss: 0.3442 - val_accuracy: 0.9045\n",
      "Epoch 5/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.3142 - accuracy: 0.9199\n",
      "Epoch 5: val_accuracy improved from 0.90452 to 0.93581, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.3135 - accuracy: 0.9201 - val_loss: 0.2687 - val_accuracy: 0.9358\n",
      "Epoch 6/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.9293\n",
      "Epoch 6: val_accuracy did not improve from 0.93581\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.2478 - accuracy: 0.9289 - val_loss: 0.2134 - val_accuracy: 0.9326\n",
      "Epoch 7/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9318\n",
      "Epoch 7: val_accuracy improved from 0.93581 to 0.93688, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.1992 - accuracy: 0.9319 - val_loss: 0.1767 - val_accuracy: 0.9369\n",
      "Epoch 8/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9407\n",
      "Epoch 8: val_accuracy improved from 0.93688 to 0.94357, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.1671 - accuracy: 0.9411 - val_loss: 0.1520 - val_accuracy: 0.9436\n",
      "Epoch 9/50\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9491\n",
      "Epoch 9: val_accuracy improved from 0.94357 to 0.95373, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.1438 - accuracy: 0.9491 - val_loss: 0.1350 - val_accuracy: 0.9537\n",
      "Epoch 10/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9569\n",
      "Epoch 10: val_accuracy improved from 0.95373 to 0.95774, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.1274 - accuracy: 0.9572 - val_loss: 0.1205 - val_accuracy: 0.9577\n",
      "Epoch 11/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9621\n",
      "Epoch 11: val_accuracy improved from 0.95774 to 0.96015, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.1137 - accuracy: 0.9619 - val_loss: 0.1094 - val_accuracy: 0.9601\n",
      "Epoch 12/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9660\n",
      "Epoch 12: val_accuracy improved from 0.96015 to 0.96496, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.1029 - accuracy: 0.9661 - val_loss: 0.0997 - val_accuracy: 0.9650\n",
      "Epoch 13/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9692\n",
      "Epoch 13: val_accuracy improved from 0.96496 to 0.96657, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0939 - accuracy: 0.9692 - val_loss: 0.0936 - val_accuracy: 0.9666\n",
      "Epoch 14/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9705\n",
      "Epoch 14: val_accuracy improved from 0.96657 to 0.96710, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0872 - accuracy: 0.9704 - val_loss: 0.0867 - val_accuracy: 0.9671\n",
      "Epoch 15/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.0816 - accuracy: 0.9714\n",
      "Epoch 15: val_accuracy improved from 0.96710 to 0.97192, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0817 - accuracy: 0.9715 - val_loss: 0.0825 - val_accuracy: 0.9719\n",
      "Epoch 16/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9748\n",
      "Epoch 16: val_accuracy did not improve from 0.97192\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0770 - accuracy: 0.9742 - val_loss: 0.0783 - val_accuracy: 0.9714\n",
      "Epoch 17/50\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9746\n",
      "Epoch 17: val_accuracy improved from 0.97192 to 0.97325, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0734 - accuracy: 0.9748 - val_loss: 0.0751 - val_accuracy: 0.9733\n",
      "Epoch 18/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9758\n",
      "Epoch 18: val_accuracy improved from 0.97325 to 0.97566, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0696 - accuracy: 0.9757 - val_loss: 0.0731 - val_accuracy: 0.9757\n",
      "Epoch 19/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 0.9765\n",
      "Epoch 19: val_accuracy improved from 0.97566 to 0.97700, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0670 - accuracy: 0.9764 - val_loss: 0.0698 - val_accuracy: 0.9770\n",
      "Epoch 20/50\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9794\n",
      "Epoch 20: val_accuracy did not improve from 0.97700\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0643 - accuracy: 0.9794 - val_loss: 0.0679 - val_accuracy: 0.9754\n",
      "Epoch 21/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9786\n",
      "Epoch 21: val_accuracy did not improve from 0.97700\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0623 - accuracy: 0.9786 - val_loss: 0.0664 - val_accuracy: 0.9767\n",
      "Epoch 22/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9792\n",
      "Epoch 22: val_accuracy improved from 0.97700 to 0.97753, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0604 - accuracy: 0.9794 - val_loss: 0.0641 - val_accuracy: 0.9775\n",
      "Epoch 23/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9805\n",
      "Epoch 23: val_accuracy improved from 0.97753 to 0.97967, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0586 - accuracy: 0.9803 - val_loss: 0.0631 - val_accuracy: 0.9797\n",
      "Epoch 24/50\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9809\n",
      "Epoch 24: val_accuracy improved from 0.97967 to 0.98021, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0569 - accuracy: 0.9809 - val_loss: 0.0620 - val_accuracy: 0.9802\n",
      "Epoch 25/50\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 0.9810\n",
      "Epoch 25: val_accuracy did not improve from 0.98021\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.0602 - val_accuracy: 0.9797\n",
      "Epoch 26/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9812\n",
      "Epoch 26: val_accuracy did not improve from 0.98021\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.0608 - val_accuracy: 0.9802\n",
      "Epoch 27/50\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9820\n",
      "Epoch 27: val_accuracy did not improve from 0.98021\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0524 - accuracy: 0.9820 - val_loss: 0.0591 - val_accuracy: 0.9789\n",
      "Epoch 28/50\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9826\n",
      "Epoch 28: val_accuracy did not improve from 0.98021\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0513 - accuracy: 0.9826 - val_loss: 0.0579 - val_accuracy: 0.9791\n",
      "Epoch 29/50\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9817\n",
      "Epoch 29: val_accuracy did not improve from 0.98021\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0504 - accuracy: 0.9818 - val_loss: 0.0570 - val_accuracy: 0.9802\n",
      "Epoch 30/50\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9823\n",
      "Epoch 30: val_accuracy improved from 0.98021 to 0.98048, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0492 - accuracy: 0.9823 - val_loss: 0.0564 - val_accuracy: 0.9805\n",
      "Epoch 31/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9822\n",
      "Epoch 31: val_accuracy improved from 0.98048 to 0.98181, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0480 - accuracy: 0.9820 - val_loss: 0.0564 - val_accuracy: 0.9818\n",
      "Epoch 32/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9819\n",
      "Epoch 32: val_accuracy did not improve from 0.98181\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0470 - accuracy: 0.9819 - val_loss: 0.0558 - val_accuracy: 0.9807\n",
      "Epoch 33/50\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9828\n",
      "Epoch 33: val_accuracy did not improve from 0.98181\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0465 - accuracy: 0.9828 - val_loss: 0.0545 - val_accuracy: 0.9813\n",
      "Epoch 34/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9838\n",
      "Epoch 34: val_accuracy did not improve from 0.98181\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0449 - accuracy: 0.9838 - val_loss: 0.0543 - val_accuracy: 0.9815\n",
      "Epoch 35/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 0.9832\n",
      "Epoch 35: val_accuracy improved from 0.98181 to 0.98235, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.0440 - accuracy: 0.9834 - val_loss: 0.0541 - val_accuracy: 0.9823\n",
      "Epoch 36/50\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9839\n",
      "Epoch 36: val_accuracy did not improve from 0.98235\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0436 - accuracy: 0.9840 - val_loss: 0.0533 - val_accuracy: 0.9821\n",
      "Epoch 37/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9839\n",
      "Epoch 37: val_accuracy did not improve from 0.98235\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0426 - accuracy: 0.9840 - val_loss: 0.0537 - val_accuracy: 0.9815\n",
      "Epoch 38/50\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9849\n",
      "Epoch 38: val_accuracy did not improve from 0.98235\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0420 - accuracy: 0.9848 - val_loss: 0.0531 - val_accuracy: 0.9821\n",
      "Epoch 39/50\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9854\n",
      "Epoch 39: val_accuracy improved from 0.98235 to 0.98262, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0413 - accuracy: 0.9854 - val_loss: 0.0521 - val_accuracy: 0.9826\n",
      "Epoch 40/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9856\n",
      "Epoch 40: val_accuracy did not improve from 0.98262\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 0.0521 - val_accuracy: 0.9826\n",
      "Epoch 41/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9863\n",
      "Epoch 41: val_accuracy did not improve from 0.98262\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.0521 - val_accuracy: 0.9826\n",
      "Epoch 42/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9857\n",
      "Epoch 42: val_accuracy improved from 0.98262 to 0.98369, saving model to classifier-putinG20-BiGRU_04.h5\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0396 - accuracy: 0.9856 - val_loss: 0.0518 - val_accuracy: 0.9837\n",
      "Epoch 43/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9873\n",
      "Epoch 43: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.0514 - val_accuracy: 0.9826\n",
      "Epoch 44/50\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9867\n",
      "Epoch 44: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0381 - accuracy: 0.9868 - val_loss: 0.0512 - val_accuracy: 0.9832\n",
      "Epoch 45/50\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9873\n",
      "Epoch 45: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 0.0511 - val_accuracy: 0.9818\n",
      "Epoch 46/50\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9870\n",
      "Epoch 46: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.0515 - val_accuracy: 0.9821\n",
      "Epoch 47/50\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9882\n",
      "Epoch 47: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.0506 - val_accuracy: 0.9826\n",
      "Epoch 48/50\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.0357 - accuracy: 0.9882\n",
      "Epoch 48: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.0506 - val_accuracy: 0.9829\n",
      "Epoch 49/50\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9886\n",
      "Epoch 49: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.0511 - val_accuracy: 0.9834\n",
      "Epoch 50/50\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9882\n",
      "Epoch 50: val_accuracy did not improve from 0.98369\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.0501 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "historyGRU = modelGRU.fit(train_padded_seq, \n",
    "                        train_label_seq, \n",
    "                        epochs=50,\n",
    "                        callbacks = [mc],\n",
    "                        # callbacks = [mc, callbacks],  \n",
    "                        validation_data=(val_padded_seq, val_label_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graphs(historyGRU, metric):\n",
    "    plt.plot(historyGRU.history[metric])\n",
    "    plt.plot(historyGRU.history[f'val_{metric}'])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, f'val_{metric}'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(historyGRU, \"accuracy\")\n",
    "plot_graphs(historyGRU, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vladimir putin not allowed g20\n",
      "Neutral\n",
      "[0]\n",
      "[9.9826592e-01 1.0757669e-03 6.5826665e-04]\n"
     ]
    }
   ],
   "source": [
    "predictions = modelGRU.predict(train_padded_seq)\n",
    "\n",
    "print(train_sentences[1])\n",
    "print(train_labels[1])\n",
    "print(train_label_seq[1])\n",
    "\n",
    "print(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 1s 6ms/step - loss: 0.0501 - accuracy: 0.9821\n",
      "[[1740   11    9]\n",
      " [  12 1452   12]\n",
      " [   7   16  480]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1760\n",
      "           1       0.98      0.98      0.98      1476\n",
      "           2       0.96      0.95      0.96       503\n",
      "\n",
      "    accuracy                           0.98      3739\n",
      "   macro avg       0.98      0.98      0.98      3739\n",
      "weighted avg       0.98      0.98      0.98      3739\n",
      "\n",
      "0.9820807576179504\n",
      "Accuracy is: 0.9820807702594276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "score = modelGRU.evaluate(val_padded_seq, val_label_seq, verbose = 1)\n",
    "\n",
    "akurasi = score[1]\n",
    "scores.append(akurasi)\n",
    "y_pred = modelGRU.predict(val_padded_seq)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "cm = confusion_matrix(val_label_seq, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(val_label_seq,y_pred))\n",
    "\n",
    "def Average(lst):\n",
    " return sum(lst) / len(lst)\n",
    "\n",
    "print(Average(scores))\n",
    "ac= accuracy_score(val_label_seq, y_pred)\n",
    "print('Accuracy is:', ac)\n",
    "sns.heatmap(cm,annot=True,fmt='d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model for Summary ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 45, 16)            8000      \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               9600      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,011\n",
      "Trainable params: 18,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('./classifier-putinG20-BiGRU_01-callback.h5')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 2s 5ms/step - loss: 0.1209 - accuracy: 0.9559\n",
      "[[1713   20   27]\n",
      " [  23 1421   32]\n",
      " [  32   31  440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1760\n",
      "           1       0.97      0.96      0.96      1476\n",
      "           2       0.88      0.87      0.88       503\n",
      "\n",
      "    accuracy                           0.96      3739\n",
      "   macro avg       0.94      0.94      0.94      3739\n",
      "weighted avg       0.96      0.96      0.96      3739\n",
      "\n",
      "0.9558705687522888\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "score = new_model.evaluate(val_padded_seq, val_label_seq, verbose = 1)\n",
    "\n",
    "akurasi = score[1]\n",
    "scores.append(akurasi)\n",
    "y_pred = new_model.predict(val_padded_seq)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "cm = confusion_matrix(val_label_seq, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(val_label_seq,y_pred))\n",
    "\n",
    "def Average(lst):\n",
    " return sum(lst) / len(lst)\n",
    "\n",
    "print(Average(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pydot\n",
    "# %pip install pydotplus\n",
    "# %pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(new_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "553094d2a8608aafcce44b005fb76f62d6125bfeaaefdeaf2e3158154b755fc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
