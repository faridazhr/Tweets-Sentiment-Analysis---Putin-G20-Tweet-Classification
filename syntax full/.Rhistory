#Loading Package
library(textclean)
library(katadasaR)
installed.packages('katadasaR')
installed.packages('katadasaR')
library(katadasaR)
library(tokenizers)
library(wordcloud)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(readr)
library(tidytext)
library(stopwords)
library(tm)
library(readr)
library(timeSeries)
library(graphics)
library(ggplot2)
library(ggfortify)
library(TSstudio)
library(tibble)
# import data
data <- read.csv("datafixsentimen.csv",stringsAsFactors=TRUE)
# import data
data <- read.csv(".\datafixsentimen.csv",stringsAsFactors=TRUE)
# import data
data <- read.csv("./datafixsentimen.csv",stringsAsFactors=TRUE)
str(data)
library(datetime)
library(xts)
data$created_at = as.date(data$created_at)
library(anytime)
datetime1 = strptime(x = as.character(data$created_at),
format = "%m/%d/%Y %H:%M")
data$created_at=datetime1
##visualisasi time series
ts_plot(data, "1 hour") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Distribution of Tweets regarding the Jokowi Issue 3 Periods for the last 1 Week",
subtitle = "Twitter status (tweet) counts aggregated using three-hour intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
help(ts_plot)
## Preprocessing Data ##
#Hilangkan redundant data
dim(data)
data_NoRed <- data %>%
distinct(id,.keep_all = T)
glimpse(data_NoRed)
dim(data_NoRed)
#Pre-Cleaning
tweets=data_NoRed$text
clean.text = function(x)
{
# remove rt
x = gsub("RT", "", x)
# remove at
x = gsub("@\\w+", "", x)
#remove hashtag
x = gsub('#\\S+', "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
# convert to lower case
x = tolower(x)
# some other cleaning text
x = gsub('https://','',x)
x = gsub('http://','',x)
x = gsub('[^[:graph:]]', ' ',x)
x = gsub('[[:punct:]]', '', x)
x = gsub('[[:cntrl:]]', '', x)
x = gsub('\\d+', '', x)
x = str_replace_all(x,"[^[:graph:]]", " ")
return(x)
}
cleantweet=clean.text(tweets)
#Coba liat berubah ngga
tweets[2]
cleantweet[2]
#Kembalikan tweet yang pre-cleaning ke Nored
data_NoRed$text=cleantweet
# Pilih atribut yang dianalsis
data_selected <- data_NoRed %>%
select(id, screen_name, text,retweet_count, favorite_count)
# Mengubah data dalam bentuk corpus
data_corpus <- VCorpus(VectorSource(data_selected$text))
# atur meta untuk data corpus
meta(data_corpus, "retweetCount") <- data_selected$retweetCount
meta(data_corpus, "favoriteCount") <- data_selected$favoriteCount
#import stopwords
file <- "https://raw.githubusercontent.com/masdevid/ID-Stopwords/master/id.stopwords.02.01.2016.txt"
stop_words <- read.delim(url(file))
names(stop_words) <- "word"
stop_words <- as_tibble(stop_words)
stop_words <-stop_words$word
tweets
cleantweet
